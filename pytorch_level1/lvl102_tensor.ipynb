{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch 텐서 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vector, Matrix, Tensor\n",
    "- 텐서\n",
    "\t- 1차원 - 벡터\n",
    "\t- 2차원 - 매트릭트\n",
    "\t- 3차원이상 - 텐서\n",
    "\n",
    "\t<img src=\"https://raw.githubusercontent.com/hugoMGSung/study-pytorch/main/images/torch0003.png\" width=\"730\">\n",
    "\n",
    "\n",
    "- Numpy는 n차원 배열 객체생성과 조작을 위한 다양한 함수를 제공. 연산 그래프나 딥러닝, 변화도 등은 알지 못함.\n",
    "- GPU를 사용한 수치 연산 가속화 불가능\n",
    "- PyTorch 모델의 입력, 출력, 모델 매개변수의 인코드 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 3., 5.])\n"
     ]
    }
   ],
   "source": [
    "basic_data = [1,3,5]\n",
    "tensor_data1 = torch.Tensor(basic_data) # vector\n",
    "\n",
    "print(tensor_data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor type : <class 'torch.Tensor'>, tensor shape : torch.Size([3])\n",
      "tensor dtype : torch.float32, tensor device : cpu\n"
     ]
    }
   ],
   "source": [
    "print(f'tensor type : {type(tensor_data1)}, tensor shape : {tensor_data1.shape}')\n",
    "print(f'tensor dtype : {tensor_data1.dtype}, tensor device : {tensor_data1.device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GPU 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor type : <class 'torch.Tensor'>, tensor shape : torch.Size([3])\n",
      "tensor dtype : torch.float32, tensor device : cuda:0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "\ttensor_data = tensor_data1.to('cuda')\n",
    "\n",
    "print(f'tensor type : {type(tensor_data)}, tensor shape : {tensor_data.shape}')\n",
    "print(f'tensor dtype : {tensor_data.dtype}, tensor device : {tensor_data.device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  2.,  4.],\n",
      "        [ 6.,  8., 10.]], device='cuda:0')\n",
      "tensor type : <class 'torch.Tensor'>, tensor shape : torch.Size([2, 3])\n",
      "tensor dtype : torch.float32, tensor device : cuda:0\n"
     ]
    }
   ],
   "source": [
    "basic_data = [ [0, 2, 4], [6, 8, 10] ]\n",
    "tensor_data1 = torch.Tensor(basic_data)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "\ttensor_data = tensor_data1.to('cuda')\n",
    "\t\n",
    "print(tensor_data)\n",
    "\n",
    "print(f'tensor type : {type(tensor_data)}, tensor shape : {tensor_data.shape}')\n",
    "print(f'tensor dtype : {tensor_data.dtype}, tensor device : {tensor_data.device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  2  4]\n",
      " [ 6  8 10]]\n",
      "tensor([[ 0,  2,  4],\n",
      "        [ 6,  8, 10]], dtype=torch.int32)\n",
      "tensor dtype : torch.int32, tensor device : cpu\n"
     ]
    }
   ],
   "source": [
    "np_data = np.array(basic_data)\n",
    "\n",
    "print(np_data)\n",
    "\n",
    "tensor_data2 = torch.from_numpy(np_data) # 기본은 float()\n",
    "\n",
    "print(tensor_data2)\n",
    "print(f'tensor dtype : {tensor_data2.dtype}, tensor device : {tensor_data2.device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 텐서 연습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat1 = torch.FloatTensor([[1,2], [3,4]])\n",
    "mat2 = torch.IntTensor([[1,2], [3,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n",
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "print(mat1.shape)\n",
    "print(mat2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.FloatTensor\n",
      "torch.IntTensor\n"
     ]
    }
   ],
   "source": [
    "print(mat1.type())\n",
    "print(mat2.type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat1 = torch.FloatTensor([[1,2], [3,4]])\n",
    "mat2 = torch.FloatTensor([[1], [2]])\n",
    "\n",
    "mat1 = mat1.to('cuda')\n",
    "mat2 = mat2.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.],\n",
       "        [11.]], device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat1.matmul(mat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [6., 8.]], device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat1 * mat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [6., 8.]], device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat1.mul(mat2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://camo.githubusercontent.com/e76d463dd069d496943ecd10a3d8970237f7cf8b431fb5fd797f50b66bb01a8f/68747470733a2f2f77696b69646f63732e6e65742f696d616765732f706167652f35323834362f6e6577696d6167652e706e67\" Width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 기본 사용법 다시\n",
    "\n",
    "##### 텐서 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2051, 0.5971, 0.1002],\n",
       "        [0.9509, 0.3269, 0.7630]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 0에서 1사이의 랜덤숫자 생성\n",
    "torch.rand(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1616,  0.2232, -0.6556],\n",
       "        [ 0.1820,  0.3430, -0.5206]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 0에서 1사이의 정규분포로 샘플링한 랜덤숫자 생성\n",
    "torch.randn(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 4, 0],\n",
       "        [6, 6, 6]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 시작수와 종료수 사이의 랜덤숫자 생성\n",
    "torch.randint(0, 9, size=(2, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 0 초기화 텐서\n",
    "torch.zeros(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 1초기화 텐서\n",
    "torch.ones(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 0 초기화 방법2\n",
    "ref = torch.rand(4, 5)\n",
    "torch.zeros_like(ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 1 초기화 방법2\n",
    "torch.ones_like(ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 텐서 데이터타입"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.FloatTensor'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 데이터타입 확인법 / FloatTensor(기본)\n",
    "ref.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.DoubleTensor'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## DoubleTensor\n",
    "x = torch.rand(2, 3)\n",
    "x_d = x.type(dtype = torch.DoubleTensor)\n",
    "x_d.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.IntTensor'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## IntTensor\n",
    "x.type_as(torch.IntTensor()).type()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Numpy를 Tensor로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1, 2, 3],\n",
       "        [4, 5, 6]]),\n",
       " numpy.ndarray)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 넘파이로 배열 생성\n",
    "x1 = np.ndarray(shape=(2,3), dtype=int, buffer=np.array([1,2,3,4,5,6]))\n",
    "x1, type(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2, 3],\n",
       "         [4, 5, 6]], dtype=torch.int32),\n",
       " 'torch.IntTensor')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 텐서로 이동\n",
    "x2 = torch.from_numpy(x1)\n",
    "x2, x2.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1, 2, 3],\n",
       "        [4, 5, 6]]),\n",
       " numpy.ndarray)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 다시 넘파이로\n",
    "x3 = x2.numpy()\n",
    "x3, type(x3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CPU사용 GPU사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3.],\n",
       "         [4., 5., 6.]]),\n",
       " 'torch.FloatTensor')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 배열로 텐서 생성\n",
    "x4 = torch.FloatTensor([[1,2,3],[4,5,6]])\n",
    "x4, x4.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "## 디바이스 만들어놓기\n",
    "cpu = torch.device('cpu')\n",
    "gpu = torch.device('cuda')\n",
    "\n",
    "x5_normal = x4.to(cpu)\n",
    "print(x5_normal)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "\tx6_gpu = x5_normal.to(gpu)\n",
    "\tprint(x6_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 10, 20, 40]), torch.Size([20]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 텐서 크기\n",
    "x7 = torch.FloatTensor(5, 10, 20, 40)\n",
    "x7.size(), x7.size()[2:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 인덱스, 조인, 자르기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1806,  0.8735,  2.2158],\n",
       "        [-2.4749, -1.4526, -0.3232],\n",
       "        [-0.0673,  3.3029,  2.0970],\n",
       "        [-0.0226, -1.2023, -0.7906]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x8 = torch.randn(4, 3)\n",
    "x8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.4526],\n",
       "        [ 3.3029]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 앞엔 행 인덱스, 뒤는 열 인덱스\n",
    "x8[1:3, 1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.4749, -1.4526, -0.3232],\n",
       "        [-0.0673,  3.3029,  2.0970]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 아래와 동일한 기능\n",
    "x8[1:3, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.4749, -1.4526, -0.3232],\n",
       "        [-0.0673,  3.3029,  2.0970]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## index_select 함수로도 가능\n",
    "## dim : 0(행별), 1(열별), -1(마지막 차원끼리) 계산\n",
    "torch.index_select(x8, dim=0, index=torch.LongTensor([1, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3.],\n",
       "         [4., 5., 6.]]),\n",
       " tensor([[-1., -2., -3.],\n",
       "         [-4., -5., -6.]]),\n",
       " tensor([[ 1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.],\n",
       "         [-1., -2., -3.],\n",
       "         [-4., -5., -6.]]),\n",
       " tensor([[ 1.,  2.,  3., -1., -2., -3.],\n",
       "         [ 4.,  5.,  6., -4., -5., -6.]]))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Join\n",
    "x = torch.FloatTensor([[1,2,3],[4,5,6]])\n",
    "y = torch.FloatTensor([[-1,-2,-3],[-4,-5,-6]])\n",
    "z1 = torch.cat([x,y], dim=0)\n",
    "z2 = torch.cat([x,y], dim=1)\n",
    "\n",
    "x, y, z1, z2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1., 2., 3.],\n",
       "          [4., 5., 6.]],\n",
       " \n",
       "         [[1., 2., 3.],\n",
       "          [4., 5., 6.]],\n",
       " \n",
       "         [[1., 2., 3.],\n",
       "          [4., 5., 6.]],\n",
       " \n",
       "         [[1., 2., 3.],\n",
       "          [4., 5., 6.]]]),\n",
       " torch.Size([4, 2, 3]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.FloatTensor([[1,2,3],[4,5,6]])\n",
    "x_stack = torch.stack([x, x, x, x], dim=0)\n",
    "\n",
    "x_stack, x_stack.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.],\n",
       "         [-1., -2., -3.],\n",
       "         [-4., -5., -6.]]),\n",
       " tensor([[1., 2., 3.],\n",
       "         [4., 5., 6.]]),\n",
       " tensor([[-1., -2., -3.],\n",
       "         [-4., -5., -6.]]),\n",
       " tensor([[ 1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.],\n",
       "         [-1., -2., -3.],\n",
       "         [-4., -5., -6.]]),\n",
       " tensor([[ 1.],\n",
       "         [ 4.],\n",
       "         [-1.],\n",
       "         [-4.]]),\n",
       " tensor([[ 2.],\n",
       "         [ 5.],\n",
       "         [-2.],\n",
       "         [-5.]]),\n",
       " tensor([[ 3.],\n",
       "         [ 6.],\n",
       "         [-3.],\n",
       "         [-6.]]))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Slicing\n",
    "x_1, x_2 = torch.chunk(z1, 2, dim=0)\n",
    "y_1, y_2, y_3 = torch.chunk(z1, 3, dim=1)\n",
    "\n",
    "z1, x_1, x_2, z1, y_1, y_2, y_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.],\n",
      "        [-1., -2., -3.],\n",
      "        [-4., -5., -6.]])\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "tensor([[-1., -2., -3.],\n",
      "        [-4., -5., -6.]])\n",
      "\n",
      "This is y1:\n",
      "tensor([[ 1.,  2.],\n",
      "        [ 4.,  5.],\n",
      "        [-1., -2.],\n",
      "        [-4., -5.]])\n",
      "tensor([[ 3.],\n",
      "        [ 6.],\n",
      "        [-3.],\n",
      "        [-6.]])\n"
     ]
    }
   ],
   "source": [
    "x1, x2 = torch.split(z1, 2, dim=0)\n",
    "y1 = torch.split(z1, 2, dim=1) \n",
    "\n",
    "print(z1, x1, x2, sep=\"\\n\")\n",
    "\n",
    "print(\"\\nThis is y1:\")\n",
    "for i in y1:\n",
    "  print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 1, 3, 1, 4, 5]), torch.Size([10, 3, 4, 5]))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Squeezing\n",
    "## 길이가 1인 차원들은 압축하기\n",
    "x1 = torch.FloatTensor(10, 1, 3, 1, 4, 5)\n",
    "x2 = torch.squeeze(x1)\n",
    "\n",
    "x1.size(), x2.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 3, 4, 5]), torch.Size([1, 10, 3, 4, 5]))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 차원을 늘림\n",
    "x3 = torch.unsqueeze(x2, dim=0)\n",
    "\n",
    "x2.size(), x3.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 텐서값 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[7.2287, 8.2722, 1.2661],\n",
       "         [7.9687, 3.8892, 4.4951]]),\n",
       " tensor([[ 0.0611,  0.1081, -0.1068],\n",
       "         [ 0.0126,  0.0316,  0.1204]]),\n",
       " tensor([[3.1416, 3.1416, 3.1416],\n",
       "         [3.1416, 3.1416, 3.1416]]))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.init as init\n",
    "\n",
    "init1 = init.uniform_(torch.FloatTensor(2, 3), a= 0, b=9)\n",
    "\n",
    "init2 = init.normal_(torch.FloatTensor(2, 3), std=0.2)\n",
    "\n",
    "init3 = init.constant_(torch.FloatTensor(2, 3), 3.141592)\n",
    "\n",
    "init1, init2, init3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 수학연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3.],\n",
       "         [4., 5., 6.]]),\n",
       " tensor([[1., 2., 3.],\n",
       "         [4., 5., 6.]]),\n",
       " tensor([[ 2.,  4.,  6.],\n",
       "         [ 8., 10., 12.]]),\n",
       " tensor([[ 2.,  4.,  6.],\n",
       "         [ 8., 10., 12.]]),\n",
       " tensor([[0., 0., 0.],\n",
       "         [0., 0., 0.]]))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = torch.FloatTensor([[1,2,3],[4,5,6]])\n",
    "x2 = torch.FloatTensor([[1,2,3],[4,5,6]])\n",
    "add = torch.add(x1, x2)\n",
    "\n",
    "x1, x2, add, x1+x2, x1-x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  4.,  9.],\n",
       "        [16., 25., 36.]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = torch.FloatTensor([[1,2,3],[4,5,6]])\n",
    "x2 = torch.FloatTensor([[1,2,3],[4,5,6]])\n",
    "x3 = torch.mul(x1, x2)\n",
    "\n",
    "x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = torch.FloatTensor([[1,2,3],[4,5,6]])\n",
    "x2 = torch.FloatTensor([[1,2,3],[4,5,6]])\n",
    "x3 = torch.div(x1, x2)\n",
    "\n",
    "x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 3.5156, 0.0000, 4.0000],\n",
       "        [0.0000, 4.5156, 0.0000, 5.0625],\n",
       "        [0.0000, 5.3477, 0.0000, 5.6406]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = torch.FloatTensor(3, 4)\n",
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0000, 12.3596,  0.0000, 16.0000],\n",
       "         [ 0.0000, 20.3909,  0.0000, 25.6289],\n",
       "         [ 0.0000, 28.5974,  0.0000, 31.8167]]),\n",
       " tensor([[ 0.0000, 12.3596,  0.0000, 16.0000],\n",
       "         [ 0.0000, 20.3909,  0.0000, 25.6289],\n",
       "         [ 0.0000, 28.5974,  0.0000, 31.8167]]))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.pow(x1, 2), x1**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 기타 수식연산\n",
    "## torch.pow, torch.exp, torch.log, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 58.2642,   0.0000,  61.8091,   0.0000,  64.5816],\n",
       "        [ 94.5884,   0.0000, 100.3409,   0.0000, 104.8189],\n",
       "        [124.4028,   0.0000, 131.9546,   0.0000, 137.7190]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Matrix 연산\n",
    "x1 = torch.FloatTensor(3,4)\n",
    "x2 = torch.FloatTensor(4,5)\n",
    "\n",
    "torch.mm(x1,x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 기타 매트릭스\n",
    "# torch.mm, torch.bmm, torch.dot, torch.transpose"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

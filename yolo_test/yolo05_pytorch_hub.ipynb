{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch 허브\n",
    "\n",
    "- https://docs.ultralytics.com/ko/yolov5/tutorials/pytorch_hub_model_loading/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gitpython>=3.1.30 in c:\\users\\perso\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 5)) (3.1.44)\n",
      "Requirement already satisfied: matplotlib>=3.3 in c:\\users\\perso\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 6)) (3.10.0)\n",
      "Requirement already satisfied: numpy>=1.23.5 in c:\\users\\perso\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 7)) (1.26.3)\n",
      "Requirement already satisfied: opencv-python>=4.1.1 in c:\\users\\perso\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 8)) (4.10.0.84)\n",
      "Requirement already satisfied: pillow>=10.3.0 in c:\\users\\perso\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 9)) (11.1.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\perso\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 10)) (6.1.1)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in c:\\users\\perso\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 11)) (6.0)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\perso\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 12)) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\perso\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 13)) (1.14.1)\n",
      "Collecting thop>=0.1.1 (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 14))\n",
      "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\perso\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (2.5.1+cu124)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\perso\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 16)) (0.20.1+cu124)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\perso\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 17)) (4.66.5)\n",
      "Requirement already satisfied: ultralytics>=8.2.34 in c:\\users\\perso\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 18)) (8.3.56)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\perso\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 27)) (2.2.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\perso\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 28)) (0.13.2)\n",
      "Requirement already satisfied: setuptools>=70.0.0 in c:\\users\\perso\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 42)) (75.6.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\perso\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from gitpython>=3.1.30->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 5)) (4.0.12)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\perso\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from matplotlib>=3.3->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 6)) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\perso\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from matplotlib>=3.3->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 6)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\perso\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from matplotlib>=3.3->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 6)) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\perso\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from matplotlib>=3.3->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 6)) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\perso\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from matplotlib>=3.3->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 6)) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\perso\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from matplotlib>=3.3->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 6)) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\perso\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from matplotlib>=3.3->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 6)) (2.9.0.post0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\perso\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from requests>=2.32.2->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 12)) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\perso\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from requests>=2.32.2->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 12)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\perso\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from requests>=2.32.2->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 12)) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\perso\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from requests>=2.32.2->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 12)) (2022.12.7)\n",
      "Requirement already satisfied: filelock in c:\\users\\perso\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\perso\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\perso\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\perso\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\perso\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (2024.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\perso\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\perso\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from sympy==1.13.1->torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\perso\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from tqdm>=4.66.3->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 17)) (0.4.6)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\perso\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from ultralytics>=8.2.34->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 18)) (9.0.0)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in c:\\users\\perso\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from ultralytics>=8.2.34->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 18)) (2.0.13)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\perso\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from pandas>=1.1.4->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 27)) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\perso\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from pandas>=1.1.4->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 27)) (2024.2)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\perso\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 5)) (5.0.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\perso\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 6)) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\perso\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from jinja2->torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (2.1.5)\n",
      "Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: thop\n",
      "Successfully installed thop-0.1.1.post2209072238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PyTorch 허브에 YOLOv5 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\perso/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2025-1-2 Python-3.11.9 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce GTX 1650 with Max-Q Design, 4096MiB)\n",
      "\n",
      "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to yolov5s.pt...\n",
      "100%|██████████| 14.1M/14.1M [00:00<00:00, 47.7MB/s]\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n",
      "C:\\Users\\perso/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>confidence</th>\n",
       "      <th>class</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>745.578735</td>\n",
       "      <td>48.470215</td>\n",
       "      <td>1142.694336</td>\n",
       "      <td>720.000000</td>\n",
       "      <td>0.868910</td>\n",
       "      <td>0</td>\n",
       "      <td>person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>124.744019</td>\n",
       "      <td>197.334473</td>\n",
       "      <td>844.397583</td>\n",
       "      <td>716.650635</td>\n",
       "      <td>0.630325</td>\n",
       "      <td>0</td>\n",
       "      <td>person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>441.238739</td>\n",
       "      <td>439.350616</td>\n",
       "      <td>498.380768</td>\n",
       "      <td>708.570923</td>\n",
       "      <td>0.616792</td>\n",
       "      <td>27</td>\n",
       "      <td>tie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>594.081787</td>\n",
       "      <td>377.300354</td>\n",
       "      <td>635.423950</td>\n",
       "      <td>437.147827</td>\n",
       "      <td>0.274014</td>\n",
       "      <td>67</td>\n",
       "      <td>cell phone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         xmin        ymin         xmax        ymax  confidence  class  \\\n",
       "0  745.578735   48.470215  1142.694336  720.000000    0.868910      0   \n",
       "1  124.744019  197.334473   844.397583  716.650635    0.630325      0   \n",
       "2  441.238739  439.350616   498.380768  708.570923    0.616792     27   \n",
       "3  594.081787  377.300354   635.423950  437.147827    0.274014     67   \n",
       "\n",
       "         name  \n",
       "0      person  \n",
       "1      person  \n",
       "2         tie  \n",
       "3  cell phone  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model\n",
    "model = torch.hub.load(\"ultralytics/yolov5\", \"yolov5s\")\n",
    "\n",
    "# Image\n",
    "im = \"https://ultralytics.com/images/zidane.jpg\"\n",
    "\n",
    "# Inference\n",
    "results = model(im)\n",
    "\n",
    "results.pandas().xyxy[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 자세한 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\perso/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2025-1-2 Python-3.11.9 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce GTX 1650 with Max-Q Design, 4096MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n",
      "100%|██████████| 49.2k/49.2k [00:00<00:00, 3.73MB/s]\n",
      "100%|██████████| 134k/134k [00:00<00:00, 4.76MB/s]\n",
      "C:\\Users\\perso/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n",
      "image 1/2: 720x1280 2 persons, 1 tie, 1 cell phone\n",
      "image 2/2: 1080x810 4 persons, 1 bus\n",
      "Speed: 8.5ms pre-process, 34.8ms inference, 108.1ms NMS per image at shape (2, 3, 640, 640)\n",
      "Saved 2 images to \u001b[1mruns\\detect\\exp\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>confidence</th>\n",
       "      <th>class</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>744.907715</td>\n",
       "      <td>47.730957</td>\n",
       "      <td>1142.076172</td>\n",
       "      <td>716.559448</td>\n",
       "      <td>0.867366</td>\n",
       "      <td>0</td>\n",
       "      <td>person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>127.860870</td>\n",
       "      <td>197.634583</td>\n",
       "      <td>845.973877</td>\n",
       "      <td>710.378113</td>\n",
       "      <td>0.637458</td>\n",
       "      <td>0</td>\n",
       "      <td>person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>441.277222</td>\n",
       "      <td>439.579651</td>\n",
       "      <td>498.367310</td>\n",
       "      <td>708.055603</td>\n",
       "      <td>0.635027</td>\n",
       "      <td>27</td>\n",
       "      <td>tie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>594.006104</td>\n",
       "      <td>376.740356</td>\n",
       "      <td>635.635010</td>\n",
       "      <td>437.111206</td>\n",
       "      <td>0.277625</td>\n",
       "      <td>67</td>\n",
       "      <td>cell phone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         xmin        ymin         xmax        ymax  confidence  class  \\\n",
       "0  744.907715   47.730957  1142.076172  716.559448    0.867366      0   \n",
       "1  127.860870  197.634583   845.973877  710.378113    0.637458      0   \n",
       "2  441.277222  439.579651   498.367310  708.055603    0.635027     27   \n",
       "3  594.006104  376.740356   635.635010  437.111206    0.277625     67   \n",
       "\n",
       "         name  \n",
       "0      person  \n",
       "1      person  \n",
       "2         tie  \n",
       "3  cell phone  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model\n",
    "model = torch.hub.load(\"ultralytics/yolov5\", \"yolov5s\")\n",
    "\n",
    "# Images\n",
    "for f in \"zidane.jpg\", \"bus.jpg\":\n",
    "    torch.hub.download_url_to_file(\"https://ultralytics.com/images/\" + f, f)  # download 2 images\n",
    "im1 = Image.open(\"zidane.jpg\")  # PIL image\n",
    "im2 = cv2.imread(\"bus.jpg\")[..., ::-1]  # OpenCV image (BGR to RGB)\n",
    "\n",
    "# Inference\n",
    "results = model([im1, im2], size=640)  # batch of images\n",
    "\n",
    "# Results\n",
    "results.print()\n",
    "results.save()  # or .show()\n",
    "\n",
    "results.xyxy[0]  # im1 predictions (tensor)\n",
    "results.pandas().xyxy[0]  # im1 predictions (pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 추론 설정\n",
    "\n",
    "YOLOv5 모델에는 신뢰도 임계값, IoU 임계값 등과 같은 다양한 추론 속성이 포함되어 있으며, 이를 설정할 수 있습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\perso/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    }
   ],
   "source": [
    "model.conf = 0.25  # NMS confidence threshold\n",
    "iou = 0.45  # NMS IoU threshold\n",
    "agnostic = False  # NMS class-agnostic\n",
    "multi_label = False  # NMS multiple labels per box\n",
    "classes = None  # (optional list) filter by class, i.e. = [0, 15, 16] for COCO persons, cats and dogs\n",
    "max_det = 1000  # maximum number of detections per image\n",
    "amp = False  # Automatic Mixed Precision (AMP) inference\n",
    "\n",
    "results = model(im, size=320)  # custom inference size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 장치\n",
    "\n",
    "모델은 생성 후 모든 디바이스로 전송할 수 있습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoShape(\n",
       "  (model): DetectMultiBackend(\n",
       "    (model): DetectionModel(\n",
       "      (model): Sequential(\n",
       "        (0): Conv(\n",
       "          (conv): Conv2d(3, 32, kernel_size=(6, 6), stride=(2, 2), padding=(2, 2))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv(\n",
       "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (2): C3(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): Conv(\n",
       "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (4): C3(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (5): Conv(\n",
       "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (6): C3(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (7): Conv(\n",
       "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (8): C3(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (9): SPPF(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (10): Conv(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (11): Upsample(scale_factor=2.0, mode='nearest')\n",
       "        (12): Concat()\n",
       "        (13): C3(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (14): Conv(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (15): Upsample(scale_factor=2.0, mode='nearest')\n",
       "        (16): Concat()\n",
       "        (17): C3(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (18): Conv(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (19): Concat()\n",
       "        (20): C3(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (21): Conv(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (22): Concat()\n",
       "        (23): C3(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (24): Detect(\n",
       "          (m): ModuleList(\n",
       "            (0): Conv2d(128, 255, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): Conv2d(256, 255, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (2): Conv2d(512, 255, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cpu()  # CPU\n",
    "model.cuda()  # GPU\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model.to(device)  # i.e. device=torch.device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델을 직접 만들 수도 있습니다. device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\perso/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2025-1-2 Python-3.11.9 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce GTX 1650 with Max-Q Design, 4096MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load(\"ultralytics/yolov5\", \"yolov5s\", device=device)  # load on CPU. device=device or device='cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 무음 출력\n",
    "\n",
    "다음을 사용하여 모델을 자동으로 로드할 수 있습니다. `_verbose=False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\perso/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2025-1-2 Python-3.11.9 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce GTX 1650 with Max-Q Design, 4096MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load(\"ultralytics/yolov5\", \"yolov5s\", _verbose=False)  # load silently"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 입력 채널\n",
    "\n",
    "기본 3개가 아닌 4개의 입력 채널로 사전 학습된 YOLOv5s 모델을 로드합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\perso/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2025-1-2 Python-3.11.9 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce GTX 1650 with Max-Q Design, 4096MiB)\n",
      "\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      4672  models.common.Conv                      [4, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1    229245  models.yolo.Detect                      [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "YOLOv5s summary: 214 layers, 7236541 parameters, 7236541 gradients, 16.9 GFLOPs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load(\"ultralytics/yolov5\", \"yolov5s\", channels=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 클래스 수\n",
    "\n",
    "기본값 80이 아닌 10개의 출력 클래스로 사전 학습된 YOLOv5s 모델을 로드합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\perso/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2025-1-2 Python-3.11.9 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce GTX 1650 with Max-Q Design, 4096MiB)\n",
      "\n",
      "Overriding model.yaml nc=80 with nc=10\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     40455  models.yolo.Detect                      [10, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "YOLOv5s summary: 214 layers, 7046599 parameters, 7046599 gradients, 16.0 GFLOPs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load(\"ultralytics/yolov5\", \"yolov5s\", classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 강제 리로드\n",
    "\n",
    "위의 단계에서 문제가 발생하면 설정 `force_reload=True` 기존 캐시를 삭제하고 PyTorch 허브에서 최신 YOLOv5 버전을 강제로 새로 다운로드하면 도움이 될 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to C:\\Users\\perso/.cache\\torch\\hub\\master.zip\n",
      "YOLOv5  2025-1-28 Python-3.11.9 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce GTX 1650 with Max-Q Design, 4096MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load(\"ultralytics/yolov5\", \"yolov5s\", force_reload=True)  # force reload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 스크린샷 추론\n",
    "\n",
    "데스크톱 화면에서 추론을 실행하려면 다음과 같이 하세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\perso/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2025-1-28 Python-3.11.9 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce GTX 1650 with Max-Q Design, 4096MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n",
      "C:\\Users\\perso/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import ImageGrab\n",
    "\n",
    "# Model\n",
    "model = torch.hub.load(\"ultralytics/yolov5\", \"yolov5s\")\n",
    "\n",
    "# Image\n",
    "im = ImageGrab.grab()  # take a screenshot\n",
    "\n",
    "# Inference\n",
    "results = model(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 다중GPU 추론\n",
    "\n",
    "YOLOv5 모델을 스레드 추론을 통해 여러 GPU에 병렬로 로드할 수 있습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\perso/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2025-1-28 Python-3.11.9 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce GTX 1650 with Max-Q Design, 4096MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n",
      "Using cache found in C:\\Users\\perso/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2025-1-28 Python-3.11.9 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce GTX 1650 with Max-Q Design, 4096MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\perso/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n",
      "C:\\Users\\perso/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n",
      "Saved 1 image to \u001b[1mruns\\detect\\exp4\u001b[0m\n",
      "Saved 1 image to \u001b[1mruns\\detect\\exp5\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "def run(model, im):\n",
    "    \"\"\"Performs inference on an image using a given model and saves the output; model must support `.save()` method.\"\"\"\n",
    "    results = model(im)\n",
    "    results.save()\n",
    "\n",
    "\n",
    "# Models\n",
    "model0 = torch.hub.load(\"ultralytics/yolov5\", \"yolov5s\", device=device)\n",
    "model1 = torch.hub.load(\"ultralytics/yolov5\", \"yolov5s\", device=device)\n",
    "\n",
    "# Inference\n",
    "threading.Thread(target=run, args=[model0, \"https://ultralytics.com/images/zidane.jpg\"], daemon=True).start()\n",
    "threading.Thread(target=run, args=[model1, \"https://ultralytics.com/images/bus.jpg\"], daemon=True).start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이전보다 퍼센트가 올라감"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

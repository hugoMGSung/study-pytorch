{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 과 DataLoader\n",
    "\n",
    "#### Dataset\n",
    "\n",
    "머신러닝, 딥러닝 학습에 사용되는 방대한 데이터의 크기 때문에 데이터를 한 번에 불러오기 쉽지 않습니다. 따라서 데이터를 한 번에 부르지 않고 하나씩만 불러서 쓰는 방식을 택해야 합니다. 모든 데이터를 불러놓고 사용하는 기존의 Dataset 말고 Custom Dataset 이 필요합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 템플릿\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        # 생성자, 데이터를 전처리 하는 부분\n",
    "        pass\n",
    "\n",
    "    def __len__(self):\n",
    "        # 데이터셋의 총 길이를 반환하는 부분\n",
    "        pass\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        # idx(인덱스)에 해당하는 입출력 데이터를 반환\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 선형 회귀를 위해 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.x_data = [[73, 80, 75],\n",
    "                            [93, 99, 93]]\n",
    "        self.y_data = [[152], [185]]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.FloatTensor(self.x_data[idx])\n",
    "        y = torch.FloatTensor(self.y_data[idx])\n",
    "\n",
    "        return x, y\n",
    "\n",
    "dataset = CustomDataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataLoader\n",
    "\n",
    "- DataLoader는 PyTorch 데이터 로딩 유틸리티의 핵심입니다. DataLoader의 가장 중요한 인자는 데이터를 불러올 데이터셋 객체를 나타내는 데이터셋입니다.\n",
    "- DataLoader는 iterator 형식으로 데이터에 접근 하도록 하며 batch_size나 shuffle 유무를 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size = 2,\n",
    "    shuffle = True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 데이터로더 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x24ad2540750>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataLoader(dataset, batch_size=1, shuffle=False, sampler=None,\n",
    "           batch_sampler=None, num_workers=0, collate_fn=None,\n",
    "           pin_memory=False, drop_last=False, timeout=0,\n",
    "           worker_init_fn=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### collate_fn\n",
    "\n",
    "DataLoader에는 collate_fn 이라는 파라미터를 지정할 수가 있습니다. 이 파라미터를 사용하면 별도의 데이터 처리 함수를 만들 수 있으며 해당 함수 내의 처리를 데이터가 출력되기 전에 적용됩니다. 기본적으로 default_collate라는 함수는 Dataset이 반환하는 데이터 유형을 확인하고 (x_batch, y_batch) 와 같은 배치로 결합하려고 시도합니다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        \"\"\"\n",
    "        data: list of tuples, e.g., [(text1, label1), (text2, label2), ...]\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text, label = self.data[idx]\n",
    "        return text, label\n",
    "\n",
    "\n",
    "# 예시 데이터\n",
    "data = [\n",
    "    ([1., 0., 45.], 1),\n",
    "    ([2., 1., 50.], 0),\n",
    "    ([0., 3., 30.], 1),\n",
    "]\n",
    "\n",
    "# TD는 MyDataset 클래스의 인스턴스\n",
    "TD = MyDataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def collate_batch(batch):\n",
    "    word_tensor = torch.tensor([[1.], [0.], [45.]])\n",
    "    label_tensor = torch.tensor([[1.]])\n",
    "\n",
    "    text_list, classes = [], []\n",
    "    for (_text, _class) in batch:\n",
    "        text_list.append(word_tensor)\n",
    "        classes.append(label_tensor)\n",
    "        \n",
    "    text = torch.cat(text_list)\n",
    "    classes = torch.tensor(classes)\n",
    "    return text, classes\n",
    "DL_DS = DataLoader(TD, batch_size=2, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform\n",
    "\n",
    "Pytorch는 이미지 분류, segmentation, 텍스트 처리, object Identification과 같은 다양한 작업에 광범위하게 사용되는 딥 러닝 프레임워크입니다. 이러한 경우 다양한 유형의 데이터를 처리해야 합니다. 그리고 대부분의 경우 데이터가 데이터가 항상 머신러닝 알고리즘 학습에 필요한 최종 처리가 된 형태로 제공되지는 않습니다. transform 을 해서 데이터를 조작하고 학습에 적합하게 만들어야 합니다.\n",
    "\n",
    "- PyTorch의 torchvision 라이브러리는 transforms 에서 다양한 변환 기능을 제공합니다. transform을 사용하여 데이터의 일부 조작을 수행하고 훈련에 적합하게 만들 수 있습니다.\n",
    "\n",
    "    - transforms.ToTensor() - 데이터를 tensor로 바꿔준다.\n",
    "    - transforms.Normalize(mean, std, inplace=False) - 정규화\n",
    "    - transforms.ToPILImage() - csv 파일로 데이터셋을 받을 경우, PIL image로 바꿔준다.\n",
    "    - transforms.Compose - 여러 단계로 변환해야 하는 경우, Compose를 통해 여러 단계를 묶을 수 있다.\n",
    "\n",
    "Dataset 클래스의 `__getitem__` 함수내에서 데이터를 변환하여 리턴될 때 주로 사용됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms, utils\n",
    "import os\n",
    "\n",
    "class TorchvisionMaskDataset(Dataset):\n",
    "    def __init__(self, path, transform=None):\n",
    "        self.path = path\n",
    "        self.imgs = list(sorted(os.listdir(self.path)))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_image = self.imgs[idx]\n",
    "        file_label = self.imgs[idx][:-3] + 'xml'\n",
    "        img_path = os.path.join(self.path, file_image)\n",
    "        # ....\n",
    "        #....\n",
    "        target = None\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "torchvision_transform = transforms.Compose([\n",
    "    transforms.Resize((300, 300)), \n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "    transforms.RandomHorizontalFlip(p = 1),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "torchvision_dataset = TorchvisionMaskDataset(\n",
    "    path = './images/',\n",
    "    transform = torchvision_transform\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ToTensor\n",
    "    - ToTensor는 매우 일반적으로 사용되는 conversion transform입니다.\n",
    "    - `transforms.ToTensor()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Normalize\n",
    "    - Normalize 작업은 텐서를 가져와 평균 및 표준 편차로 정규화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. CenterCrop\n",
    "    - 이것은 중앙에서 주어진 텐서 이미지를 자릅니다. `transform.CenterCrop(height, width)` 형식"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. RandomHorizontalFlip\n",
    "    - 이 변환은 주어진 확률로 이미지를 무작위로 수평으로 뒤집을(flip) 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. RandomRotation\n",
    "    - 이 변환은 이미지를 각도만큼 무작위로 회전합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Grayscale\n",
    "    - 이 변환은 원본 RGB 이미지를 회색조로 변경합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. 가우시안 블러\n",
    "    - 여기에서 이미지는 무작위로 선택된 가우시안 흐림 효과로 흐려집니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. RandomApply\n",
    "    - 이 변환은 확률로 주어진 transformation 들을 무작위로 적용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.RandomApply([transforms.RandomSizedCrop(200),transforms.RandomHorizontalFlip()],p=0.6)\n",
    "tensor_img = transform(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Compose\n",
    "    - transform에 여러 단계가 있는 경우, Compose를 통해 여러 단계를 하나로 묶을 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms.Compose([ \n",
    "   transforms.ToTensor(), \n",
    "   transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) \n",
    "])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 성능 평가 및 개선\n",
    "\n",
    "### 내용\n",
    "1.  모델 성능 평가 지표\n",
    "    - 평가 지표의 중요성\n",
    "        - 모델 성능을 객관적으로 평가하기 위한 지표 필요성\n",
    "        - 다양한 지표를 통해 모델의 강점과 약점 파악\n",
    "    - 분류 문제의 평가 지표\n",
    "        - 정확도(Accuracy)\n",
    "        - 정밀도(Precision)\n",
    "        - 재현율(Recall)\n",
    "        - F1 스코어(F1 Score)\n",
    "        - ROC-AUC (Receiver Operating Characteristic - Area Under Curve)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# 예측값 생성\n",
    "y_pred = model.predict(X_test) # 모델 없음\n",
    "\n",
    "# 평가 지표 계산\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')\n",
    "print(f'ROC-AUC: {roc_auc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 회귀 문제의 평가 지표\n",
    "    - 평균 절대 오차(MAE, Mean Absolute Error)\n",
    "    - 평균 제곱 오차(MSE, Mean Squared Error)\n",
    "    - 결정 계수(R² Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# 예측값 생성\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 평가 지표 계산\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'MAE: {mae}')\n",
    "print(f'MSE: {mse}')\n",
    "print(f'R²: {r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 모델 성능 개선 방법\n",
    "    - 데이터 증강(Data Augmentation)\n",
    "        - 데이터 다양성 증가를 통한 일반화 성능 향상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 하이퍼파라미터 튜닝(Hyperparameter Tuning)\n",
    "    - 최적의 하이퍼파라미터 조합 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30]\n",
    "}\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f'Best parameters found: {grid_search.best_params_}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 앙상블 기법(Ensemble Methods)\n",
    "    - 여러 모델의 예측을 결합하여 성능 향상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "clf1 = LogisticRegression()\n",
    "clf2 = SVC(probability=True)\n",
    "clf3 = RandomForestClassifier()\n",
    "\n",
    "ensemble_model = VotingClassifier(estimators=[\n",
    "    ('lr', clf1), ('svc', clf2), ('rf', clf3)], voting='soft')\n",
    "\n",
    "ensemble_model.fit(X_train, y_train)\n",
    "y_pred = ensemble_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Ensemble model accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 프로젝트 설명 및 진행\n",
    "    - 프로젝트 개요\n",
    "        - 모델 성능 평가 및 개선을 위한 실전 프로젝트 수행\n",
    "        - 평가 지표를 사용하여 모델 성능을 측정하고, 다양한 기법을 통해 성능 개선 시도\n",
    "    - 데이터셋 선택\n",
    "        - Kaggle 또는 기타 오픈 데이터셋에서 프로젝트 데이터셋 선택\n",
    "        - CIFAR-10, Dogs vs. Cats, Titanic 등\n",
    "    - 프로젝트 단계\n",
    "        - 데이터 전처리 및 준비\n",
    "        - 모델 설계 및 학습\n",
    "        - 성능 평가 지표 적용\n",
    "        - 모델 성능 개선 기법 적용\n",
    "        - 성능 평가 및 결과 분석\n",
    "\n",
    "4. 프로젝트 예시\n",
    "    - 예시 프로젝트: CIFAR-10 이미지 분류\n",
    "        - 데이터셋 로드 및 전처리\n",
    "        - 성능 평가 지표 적용 및 모델 성능 개선 기법 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 데이터 전처리 변환\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# CIFAR-10 데이터셋 로드\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "val_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Pretrained ResNet 모델 로드 및 수정\n",
    "model = models.resnet18(pretrained=True)\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, 10)\n",
    "\n",
    "# 손실 함수와 옵티마이저 설정\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "# 학습 루프\n",
    "num_epochs = 25\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    scheduler.step()  # 학습률 갱신\n",
    "    val_loss = evaluate_model(model, val_loader)  # 검증 손실 계산\n",
    "\n",
    "    print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}, Val Loss: {val_loss}, Learning Rate: {scheduler.get_last_lr()}')\n",
    "\n",
    "# 모델 평가\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy: {accuracy}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. 프로젝트 발표 및 코드 리뷰\n",
    "    - 프로젝트 발표\n",
    "        - 각 그룹 또는 개인은 프로젝트 결과 발표\n",
    "        - 모델 설계, 훈련 과정, 성능 평가 결과 등을 공유\n",
    "    - 코드 리뷰 및 피드백\n",
    "        - 각 그룹의 코드를 리뷰하고 피드백 제공\n",
    "        - 개선할 점 및 좋은 점 공유\n",
    "\n",
    "6. 실습\n",
    "    - 다양한 성능 평가 지표를 적용하여 모델 성능 분석\n",
    "    - 모델 성능 개선 기법을 적용하여 결과 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실습 과제 예시\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# 모델 학습 및 평가\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=20)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 성능 평가 지표 계산\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델의 성능 모니터링 및 유지보수\n",
    "\n",
    "### 내용\n",
    "1. 모델 성능 모니터링의 중요성\n",
    "    - 성능 모니터링의 필요성\n",
    "        - 모델의 성능 저하 감지 및 원인 분석\n",
    "        - 실시간 예측 시스템의 신뢰성 유지\n",
    "    - 모니터링의 주요 지표\n",
    "        - 예측정확도\n",
    "        - 응답시간\n",
    "        - 자원 사용량(CPU, GPU, RAM)\n",
    "\n",
    "2. 실시간 예측 시스템 모니터링 방법\n",
    "    - 로그 수집 및 분석\n",
    "        - 예측 요청 및 응답 로그 수집\n",
    "        - 로그 분석을 통한 성능 이슈 파악"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# 로그 설정\n",
    "logging.basicConfig(filename='app.log', level=logging.INFO)\n",
    "\n",
    "# Flask 예측 함수에 로그 추가\n",
    "def get_prediction(image_bytes):\n",
    "    tensor = transform_image(image_bytes)\n",
    "    outputs = model(tensor)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    logging.info(f'Predicted: {predicted.item()}')  # 로그 추가\n",
    "    return predicted.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모니터링 도구 사용\n",
    "    - Prometheus, Grafana 등의 모니터링 도구를 사용하여 성능 지표 시각화\n",
    "    - Flask 애플리케이션에 Prometheus 클라이언트 통합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "# transform_image 함수 정의\n",
    "def transform_image(image_bytes):\n",
    "    # PIL 이미지로 변환\n",
    "    image = Image.open(image_bytes)\n",
    "    \n",
    "    # 이미지 전처리 transform 정의\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  # 이미지 크기를 224x224로 리사이즈\n",
    "        transforms.ToTensor(),  # Tensor로 변환\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 정규화\n",
    "    ])\n",
    "    \n",
    "    # 전처리된 이미지 반환\n",
    "    return transform(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prometheus_client import start_http_server, Summary\n",
    "\n",
    "# 요청 처리 시간 측정을 위한 메트릭 정의\n",
    "REQUEST_TIME = Summary('request_processing_seconds', 'Time spent processing request')\n",
    "\n",
    "@REQUEST_TIME.time()\n",
    "def get_prediction(image_bytes):\n",
    "    tensor = transform_image(image_bytes)\n",
    "    outputs = model(tensor)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    return predicted.item()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Prometheus HTTP 서버 시작\n",
    "    start_http_server(8000)\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 모델 성능 유지보수 및 업데이트 전략\n",
    "    - 성능 저하 원인 분석\n",
    "        - 데이터 분포 변화\n",
    "        - 모델 노후화\n",
    "    - 주기적 재학습 및 업데이트\n",
    "        - 새로운 데이터를 반영하여 주기적으로 모델 재학습\n",
    "        - 지속적인 성능 평가 및 모델 업데이트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrain_model(new_data, new_labels):\n",
    "    # 새로운 데이터로 모델 재학습\n",
    "    model.train()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    for epoch in range(5):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in DataLoader(TensorDataset(new_data, new_labels), batch_size=32, shuffle=True):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f'Retraining Epoch {epoch+1}, Loss: {running_loss/len(new_data)}')\n",
    "    torch.save(model, 'model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모델 버전 관리\n",
    "    - 모델 버전 번호 부여 및 관리   \n",
    "    - 모델 업데이트 시 버전 정보와 함께 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def save_model_with_version(model, version):\n",
    "    date_str = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "    model_path = f'model_v{version}_{date_str}.pth'\n",
    "    torch.save(model, model_path)\n",
    "    print(f'Model saved as {model_path}')\n",
    "\n",
    "# 모델 저장 예시\n",
    "save_model_with_version(model, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. 프로젝트 예시\n",
    "    - 예시 프로젝트: 실시간 예측 시스템 모니터링 및 유지보수\n",
    "        - 데이터셋 로드 및 전처리\n",
    "        - 모델 학습 및 배포\n",
    "        - Prometheus 및 Grafana를 이용한 성능 모니터링 설정\n",
    "        - 성능 저하 시 모델 재학습 및 업데이트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 아래의 소스를 py로 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from flask import Flask, request, jsonify\n",
    "from prometheus_client import start_http_server, Summary\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "# 데이터 전처리 변환\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((28, 28)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# MNIST 데이터셋 로드\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "val_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# 간단한 CNN 모델 정의\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 7 * 7)  # Flatten the tensor\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# 모델 학습\n",
    "model = SimpleCNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}')\n",
    "\n",
    "# 모델 저장\n",
    "torch.save(model, 'model.pth')\n",
    "\n",
    "# Flask 앱 정의\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Prometheus 설정\n",
    "REQUEST_TIME = Summary('request_processing_seconds', 'Time spent processing request')\n",
    "\n",
    "# 모델 로드\n",
    "model = torch.load('model.pth')\n",
    "model.eval()\n",
    "\n",
    "# 이미지 전처리 함수\n",
    "def transform_image(image_bytes):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((28, 28)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "    image = Image.open(io.BytesIO(image_bytes))\n",
    "    return transform(image).unsqueeze(0)\n",
    "\n",
    "# 예측 함수\n",
    "@REQUEST_TIME.time()\n",
    "def get_prediction(image_bytes):\n",
    "    tensor = transform_image(image_bytes)\n",
    "    outputs = model(tensor)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    return predicted.item()\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    if request.method == 'POST':\n",
    "        file = request.files['file']\n",
    "        img_bytes = file.read()\n",
    "        prediction = get_prediction(img_bytes)\n",
    "        return jsonify({'prediction': prediction})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start_http_server(8000)  # Prometheus HTTP 서버 시작\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. 실습 이후"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실습 과제 예시\n",
    "from flask import Flask, request, jsonify\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import io\n",
    "from prometheus_client import start_http_server, Summary\n",
    "\n",
    "# Prometheus 설정\n",
    "REQUEST_TIME = Summary('request_processing_seconds', 'Time spent processing request')\n",
    "\n",
    "# 모델 로드 및 Flask 설정\n",
    "app = Flask(__name__)\n",
    "model = torch.load('model.pth')\n",
    "model.eval()\n",
    "\n",
    "def transform_image(image_bytes):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((28, 28)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "    image = Image.open(io.BytesIO(image_bytes))\n",
    "    return transform(image).unsqueeze(0)\n",
    "\n",
    "@REQUEST_TIME.time()\n",
    "def get_prediction(image_bytes):\n",
    "    tensor = transform_image(image_bytes)\n",
    "    outputs = model(tensor)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    return predicted.item()\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    if request.method == 'POST':\n",
    "        file = request.files['file']\n",
    "        img_bytes = file.read()\n",
    "        prediction = get_prediction(img_bytes)\n",
    "        return jsonify({'prediction': prediction})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start_http_server(8000)  # Prometheus HTTP 서버 시작\n",
    "    app.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

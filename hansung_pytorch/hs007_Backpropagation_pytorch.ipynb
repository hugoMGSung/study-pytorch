{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 인공신경망\n",
    "\n",
    "### 역전파\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 다중계층 퍼셉트론 (Multi-Layer Perceptron)\n",
    "- 단일 퍼셉트론 다중으로 겹쳐 해결가능한 문제 범주를 확대\n",
    "- 복잡한 입력이 비선형 변경을 통해 분류가 쉬운 은닉 공간으로 매핑\n",
    "\n",
    "    [참조](https://colah.github.io/posts/2015-09-NN-Types-FP/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MLP 가중치 학습\n",
    "- 학습으로 최적의 가중치(w) 및 편향(b)를 계산\n",
    "- 레이어가 복잡할수록 가중치와 bias를 구하기 어려움\n",
    "- **역전파(Backpropagation) 알고리즘**으로 MLP학습\n",
    "\n",
    "##### 그래서 역전파란?\n",
    "- 모델의 잘못된 결과를 예측했다면, 어떤 가중치가 가장 큰 영향을 미쳤는지를 추적한 뒤\n",
    "- 이 가중치를 조금씩 조정하여 다음에 더 나은 결과를 만들게 하는 것\n",
    "\n",
    "- 예를 들면, 시험을 보고 틀린 문제의 원인을 분석하는 과정!\n",
    "\n",
    "##### PyTorch에서는 \n",
    "- 텐서의 모든 연산에 대한 자동 미분을 제공하며\n",
    "- 매 순간 적절한 역전파를 제공함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델저장 및 로드\n",
    "\n",
    "#### DNN(Deep Neural Network)\n",
    "- 심층신경망 - 여러 비선형 변환의 조합을 통해 높은 수준의 추상화를 시도\n",
    "    - 은닉계층으로 계속된 비선형 매핑, 목적에 맞는 특징 추출\n",
    "\n",
    "#### 모델 저장과 로드\n",
    "- 모델을 이용할 때마다 학습할 필요없음\n",
    "- 모델 학습시 시간이 많이 소요되므로 매번 학습을 하는 것은 비효율적\n",
    "\n",
    "\n",
    "#### 함수리스트\n",
    "- torch.save() - 모델전체(계층 구조, 매개변수 등) 디스크에 저장\n",
    "- torch.load() - 객체 역직렬화 후 메모리 할당\n",
    "- state_dict() - 모델의 매개변수(가중치)만을 저장/로드할 때 이용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### XOR 문제\n",
    "\n",
    "|구분|input x1|input x2|output y|\n",
    "|:---:|---:|---:|---:|\n",
    "|a|0|0|0|\n",
    "|b|1|0|1|\n",
    "|c|0|1|1|\n",
    "|d|1|1|0|\n",
    "\n",
    "\n",
    "- 구조\n",
    "\n",
    "    <img src=\"https://raw.githubusercontent.com/hugoMGSung/study-pytorch/refs/heads/main/images/torch0013.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 위의 문제를 DNN으로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.FloatTensor([[0,0],[0,1],[1,0],[1,1]]).to(device)\n",
    "Y = torch.FloatTensor([[0],[1],[1],[0]]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(2, 10, bias=True),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(10, 10, bias=True),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(10, 10, bias=True),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(10, 1, bias=True),\n",
    "    nn.Sigmoid()\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비용함수와 옵티마이저 정의\n",
    "criterion = torch.nn.BCELoss().to(device) # Binary Cross Entropy\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0000, Cost: 0.707413971\n",
      "Epoch: 0100, Cost: 0.693155587\n",
      "Epoch: 0200, Cost: 0.693154931\n",
      "Epoch: 0300, Cost: 0.693154335\n",
      "Epoch: 0400, Cost: 0.693153739\n",
      "Epoch: 0500, Cost: 0.693153083\n",
      "Epoch: 0600, Cost: 0.693152487\n",
      "Epoch: 0700, Cost: 0.693151832\n",
      "Epoch: 0800, Cost: 0.693151295\n",
      "Epoch: 0900, Cost: 0.693150699\n",
      "Epoch: 1000, Cost: 0.693150163\n",
      "Epoch: 1100, Cost: 0.693149567\n",
      "Epoch: 1200, Cost: 0.693148971\n",
      "Epoch: 1300, Cost: 0.693148434\n",
      "Epoch: 1400, Cost: 0.693147898\n",
      "Epoch: 1500, Cost: 0.693147361\n",
      "Epoch: 1600, Cost: 0.693146765\n",
      "Epoch: 1700, Cost: 0.693146229\n",
      "Epoch: 1800, Cost: 0.693145633\n",
      "Epoch: 1900, Cost: 0.693145037\n",
      "Epoch: 2000, Cost: 0.693144500\n",
      "Epoch: 2100, Cost: 0.693143845\n",
      "Epoch: 2200, Cost: 0.693143249\n",
      "Epoch: 2300, Cost: 0.693142653\n",
      "Epoch: 2400, Cost: 0.693142056\n",
      "Epoch: 2500, Cost: 0.693141401\n",
      "Epoch: 2600, Cost: 0.693140686\n",
      "Epoch: 2700, Cost: 0.693139970\n",
      "Epoch: 2800, Cost: 0.693139374\n",
      "Epoch: 2900, Cost: 0.693138599\n",
      "Epoch: 3000, Cost: 0.693137825\n",
      "Epoch: 3100, Cost: 0.693136990\n",
      "Epoch: 3200, Cost: 0.693136156\n",
      "Epoch: 3300, Cost: 0.693135262\n",
      "Epoch: 3400, Cost: 0.693134427\n",
      "Epoch: 3500, Cost: 0.693133414\n",
      "Epoch: 3600, Cost: 0.693132401\n",
      "Epoch: 3700, Cost: 0.693131268\n",
      "Epoch: 3800, Cost: 0.693130136\n",
      "Epoch: 3900, Cost: 0.693129003\n",
      "Epoch: 4000, Cost: 0.693127692\n",
      "Epoch: 4100, Cost: 0.693126321\n",
      "Epoch: 4200, Cost: 0.693124831\n",
      "Epoch: 4300, Cost: 0.693123221\n",
      "Epoch: 4400, Cost: 0.693121552\n",
      "Epoch: 4500, Cost: 0.693119764\n",
      "Epoch: 4600, Cost: 0.693117797\n",
      "Epoch: 4700, Cost: 0.693115592\n",
      "Epoch: 4800, Cost: 0.693113267\n",
      "Epoch: 4900, Cost: 0.693110764\n",
      "Epoch: 5000, Cost: 0.693107963\n",
      "Epoch: 5100, Cost: 0.693104744\n",
      "Epoch: 5200, Cost: 0.693101406\n",
      "Epoch: 5300, Cost: 0.693097591\n",
      "Epoch: 5400, Cost: 0.693093419\n",
      "Epoch: 5500, Cost: 0.693088770\n",
      "Epoch: 5600, Cost: 0.693083405\n",
      "Epoch: 5700, Cost: 0.693077445\n",
      "Epoch: 5800, Cost: 0.693070471\n",
      "Epoch: 5900, Cost: 0.693062663\n",
      "Epoch: 6000, Cost: 0.693053484\n",
      "Epoch: 6100, Cost: 0.693042815\n",
      "Epoch: 6200, Cost: 0.693030238\n",
      "Epoch: 6300, Cost: 0.693015218\n",
      "Epoch: 6400, Cost: 0.692997217\n",
      "Epoch: 6500, Cost: 0.692975104\n",
      "Epoch: 6600, Cost: 0.692947567\n",
      "Epoch: 6700, Cost: 0.692912698\n",
      "Epoch: 6800, Cost: 0.692867517\n",
      "Epoch: 6900, Cost: 0.692807376\n",
      "Epoch: 7000, Cost: 0.692724645\n",
      "Epoch: 7100, Cost: 0.692606032\n",
      "Epoch: 7200, Cost: 0.692426860\n",
      "Epoch: 7300, Cost: 0.692136645\n",
      "Epoch: 7400, Cost: 0.691618204\n",
      "Epoch: 7500, Cost: 0.690549612\n",
      "Epoch: 7600, Cost: 0.687772036\n",
      "Epoch: 7700, Cost: 0.676886082\n",
      "Epoch: 7800, Cost: 0.610865235\n",
      "Epoch: 7900, Cost: 0.509330034\n",
      "Epoch: 8000, Cost: 0.053662118\n",
      "Epoch: 8100, Cost: 0.012868511\n",
      "Epoch: 8200, Cost: 0.006585017\n",
      "Epoch: 8300, Cost: 0.004275222\n",
      "Epoch: 8400, Cost: 0.003113157\n",
      "Epoch: 8500, Cost: 0.002424559\n",
      "Epoch: 8600, Cost: 0.001973302\n",
      "Epoch: 8700, Cost: 0.001656576\n",
      "Epoch: 8800, Cost: 0.001423090\n",
      "Epoch: 8900, Cost: 0.001244374\n",
      "Epoch: 9000, Cost: 0.001103502\n",
      "Epoch: 9100, Cost: 0.000989876\n",
      "Epoch: 9200, Cost: 0.000896357\n",
      "Epoch: 9300, Cost: 0.000818191\n",
      "Epoch: 9400, Cost: 0.000751915\n",
      "Epoch: 9500, Cost: 0.000695102\n",
      "Epoch: 9600, Cost: 0.000645886\n",
      "Epoch: 9700, Cost: 0.000602849\n",
      "Epoch: 9800, Cost: 0.000564908\n",
      "Epoch: 9900, Cost: 0.000531248\n",
      "Epoch: 10000, Cost: 0.000501233\n"
     ]
    }
   ],
   "source": [
    "# 10_000번\n",
    "for epoch in range(10001):\n",
    "    optimizer.zero_grad()\n",
    "    hypothesis = model(X)\n",
    "\n",
    "    # 비용함수\n",
    "    cost = criterion(hypothesis, Y)\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch: {epoch:04d}, Cost: {cost.item():.9f}')\n",
    "        torch.save(model, f'./models/mymodel_{epoch}.pt') ## epoch 100번마다 모델 저장\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델의 출력값(Hypothesis): [[0.49993777]\n",
      " [0.49996787]\n",
      " [0.5000212 ]\n",
      " [0.5000572 ]]\n",
      "모델의 예측값(Predicted): [[0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]]\n",
      "실제값(Y): [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "정확도(Accuracy): 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\perso\\AppData\\Local\\Temp\\ipykernel_16120\\186257832.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load('./models/mymodel_1000.pt', map_location=device)\n"
     ]
    }
   ],
   "source": [
    "model = torch.load('./models/mymodel_1000.pt', map_location=device)\n",
    "with torch.no_grad():\n",
    "    hypothesis = model(X)\n",
    "    predicted = (hypothesis > 0.5).float()\n",
    "    accuracy = (predicted == Y).float().mean()\n",
    "\n",
    "    print(f'모델의 출력값(Hypothesis): {hypothesis.detach().cpu().numpy()}')\n",
    "    print(f'모델의 예측값(Predicted): {predicted.detach().cpu().numpy()}')\n",
    "    print(f'실제값(Y): {Y.cpu().numpy()}')\n",
    "    print(f'정확도(Accuracy): {accuracy.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델의 출력값(Hypothesis): [[5.6829309e-04]\n",
      " [9.9954480e-01]\n",
      " [9.9946016e-01]\n",
      " [4.3980076e-04]]\n",
      "모델의 예측값(Predicted): [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "실제값(Y): [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "정확도(Accuracy): 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\perso\\AppData\\Local\\Temp\\ipykernel_16120\\1915402402.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load('./models/mymodel_10000.pt', map_location=device)\n"
     ]
    }
   ],
   "source": [
    "model = torch.load('./models/mymodel_10000.pt', map_location=device)\n",
    "with torch.no_grad():\n",
    "    hypothesis = model(X)\n",
    "    predicted = (hypothesis > 0.5).float()\n",
    "    accuracy = (predicted == Y).float().mean()\n",
    "\n",
    "    print(f'모델의 출력값(Hypothesis): {hypothesis.detach().cpu().numpy()}')\n",
    "    print(f'모델의 예측값(Predicted): {predicted.detach().cpu().numpy()}')\n",
    "    print(f'실제값(Y): {Y.cpu().numpy()}')\n",
    "    print(f'정확도(Accuracy): {accuracy.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 인공신경망\n",
    "\n",
    "#### 드롭아웃(dropout)\n",
    "- 과대적합 방지를 위한 방법 - 학습과정에 레이어 일부를 사용하지 않는 방법\n",
    "\n",
    "#### ReLU(Rectified Linear Unit) - 정류한 선형 단위\n",
    "\n",
    "- 시그모이드 함수보다 더 발전된 활성화 함수\n",
    "- 간단하고 효과적이며, 특히 신경망 Hidden Layer에 주로 사용됨\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/hugoMGSung/study-pytorch/refs/heads/main/images/torch0014.png\" width=\"600\">\n",
    "\n",
    "##### ReLU의 역할\n",
    "- 비선형성 도입 - 신경망에서 비선형성을 제공, 단순한 선형회귀가 아닌 복잡합 패턴 학습가능케 함\n",
    "- 간결한 계산 - 다른 활성화 함수(Sigmoid, Tanh)에 비해 수식이 간단, 역전파 계산시 효율적\n",
    "\n",
    "##### 장점\n",
    "- 기울기 소실(Vanishing Gradient) 문제 완화:\n",
    "    - Sigmoid나 Tanh는 입력값이 커지거나 작아질수록 기울기가 0에 가까워져 학습이 느려지는 문제가 발생\n",
    "    - 반면, ReLU는 양수 입력에 대해 기울기가 일정(1)하므로 학습이 더 빠르게 진행가능\n",
    "- 효율성:\n",
    "    - 함수가 단순하기 때문에 계산 비용이 적음\n",
    "- 희소성(Sparsity):\n",
    "    - ReLU는 음수 값을 0으로 만들어 네트워크의 일부 뉴런을 비활성화. 이로 인해 네트워크가 더 간결하게 학습할 수 있음\n",
    "\n",
    "##### 단점\n",
    "- 죽은 ReLU(Dying ReLU):\n",
    "    - 학습 도중 일부 뉴런의 출력이 항상 0이 되어 더 이상 업데이트되지 않는 현상\n",
    "    - 이를 해결하기 위해 Leaky ReLU, Parametric ReLU(PReLU) 같은 변형된 ReLU 함수가 사용\n",
    "- 큰 입력값에서의 한계:\n",
    "    - 너무 큰 값에서는 기울기가 일정하게 유지되므로 모델이 특정 상황에서 덜 민감할 수 있슴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 인공신경망 MNIST 데이터셋\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "valid_size = 0.2\n",
    "\n",
    "# MNIST dataset\n",
    "train_data = datasets.MNIST(root='./MNIST_data/', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_data = datasets.MNIST(root='./MNIST_data/', train=False, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "## 이미 존재하므로 다시 다운로드 받지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training set의 20%를 Validation set으로 이용\n",
    "num_train = len(train_data)\n",
    "indices = list(range(num_train))\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(0.2 * num_train))\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=20, sampler=train_sampler)\n",
    "valid_loader = torch.utils.data.DataLoader(train_data, batch_size=20, sampler=valid_sampler)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(784, 512),\n",
    "    nn.ReLU(),   # Sigmoid대신 ReLU로\n",
    "    nn.Dropout(0.2), # 0.2를 Dropout 해서 과대적합 방지\n",
    "    nn.Linear(512, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(512, 10), # 최종적으로 0~9까지 분류\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training Loss: 0.7636910105595986 Validation Loss: 0.07363100003326932\n",
      "Accuracy: 89.9000015258789\n",
      "Epoch 2 Training Loss: 0.2846487508217494 Validation Loss: 0.05516631205504139\n",
      "Accuracy: 92.31999969482422\n",
      "Epoch 3 Training Loss: 0.22416970080137252 Validation Loss: 0.04500637452925245\n",
      "Accuracy: 93.58999633789062\n",
      "Epoch 4 Training Loss: 0.18544571985707928 Validation Loss: 0.03793760694718609\n",
      "Accuracy: 94.52000427246094\n",
      "Epoch 5 Training Loss: 0.15749393749050797 Validation Loss: 0.03279158041905612\n",
      "Accuracy: 95.30000305175781\n",
      "Epoch 6 Training Loss: 0.1363906393071326 Validation Loss: 0.02881580418193092\n",
      "Accuracy: 95.68000030517578\n",
      "Epoch 7 Training Loss: 0.12109160321593905 Validation Loss: 0.026346306968014686\n",
      "Accuracy: 96.0300064086914\n",
      "Epoch 8 Training Loss: 0.10934134409685309 Validation Loss: 0.023838657457071047\n",
      "Accuracy: 96.43000030517578\n",
      "Epoch 9 Training Loss: 0.09901639030439158 Validation Loss: 0.02190371003591766\n",
      "Accuracy: 96.66999816894531\n",
      "Epoch 10 Training Loss: 0.08957763870324319 Validation Loss: 0.02047851812009079\n",
      "Accuracy: 96.91000366210938\n",
      "Epoch 11 Training Loss: 0.08331259882686814 Validation Loss: 0.01917766423802823\n",
      "Accuracy: 97.08999633789062\n",
      "Epoch 12 Training Loss: 0.07468392968185557 Validation Loss: 0.018087973423535006\n",
      "Accuracy: 97.25\n",
      "Epoch 13 Training Loss: 0.07103631391205514 Validation Loss: 0.01723323475359939\n",
      "Accuracy: 97.43999481201172\n",
      "Epoch 14 Training Loss: 0.06434516005897119 Validation Loss: 0.016533444308132556\n",
      "Accuracy: 97.41999816894531\n",
      "Epoch 15 Training Loss: 0.06020194197294768 Validation Loss: 0.015653462114394643\n",
      "Accuracy: 97.47000122070312\n",
      "Epoch 16 Training Loss: 0.05676329881651327 Validation Loss: 0.015294547438931962\n",
      "Accuracy: 97.54999542236328\n",
      "Epoch 17 Training Loss: 0.05286779905987593 Validation Loss: 0.014798741051966014\n",
      "Accuracy: 97.6199951171875\n",
      "Epoch 18 Training Loss: 0.050004796957053864 Validation Loss: 0.014385069136139161\n",
      "Accuracy: 97.75999450683594\n",
      "Epoch 19 Training Loss: 0.04710836699719463 Validation Loss: 0.014287515031387253\n",
      "Accuracy: 97.72999572753906\n",
      "Epoch 20 Training Loss: 0.04428530540969223 Validation Loss: 0.013508308381055637\n",
      "Accuracy: 97.83999633789062\n",
      "Epoch 21 Training Loss: 0.04137486207469677 Validation Loss: 0.013377353766409215\n",
      "Accuracy: 97.81999969482422\n",
      "Epoch 22 Training Loss: 0.03932525645019875 Validation Loss: 0.013011935258565548\n",
      "Accuracy: 97.87999725341797\n",
      "Epoch 23 Training Loss: 0.03702390408377202 Validation Loss: 0.01269265617094546\n",
      "Accuracy: 97.90999603271484\n",
      "Epoch 24 Training Loss: 0.03504150175793135 Validation Loss: 0.012572506616900986\n",
      "Accuracy: 97.93000030517578\n",
      "Epoch 25 Training Loss: 0.032756389823528784 Validation Loss: 0.012389094386346793\n",
      "Accuracy: 97.90999603271484\n",
      "Epoch 26 Training Loss: 0.03153514532643021 Validation Loss: 0.01225690801879197\n",
      "Accuracy: 98.11000061035156\n",
      "Epoch 27 Training Loss: 0.02939013443735894 Validation Loss: 0.012512631417407345\n",
      "Accuracy: 98.04999542236328\n",
      "Epoch 28 Training Loss: 0.027868398825836874 Validation Loss: 0.01177405195144335\n",
      "Accuracy: 98.0999984741211\n",
      "Epoch 29 Training Loss: 0.026650587700559603 Validation Loss: 0.012015588667772439\n",
      "Accuracy: 98.0199966430664\n",
      "Epoch 30 Training Loss: 0.025026735258254728 Validation Loss: 0.011479233279475011\n",
      "Accuracy: 98.04999542236328\n",
      "Epoch 31 Training Loss: 0.024064505258123974 Validation Loss: 0.011816592498338043\n",
      "Accuracy: 98.18999481201172\n",
      "Epoch 32 Training Loss: 0.023083948314898104 Validation Loss: 0.01208692493213069\n",
      "Accuracy: 98.0199966430664\n",
      "Epoch 33 Training Loss: 0.02200284966052762 Validation Loss: 0.011562403789672923\n",
      "Accuracy: 98.07999420166016\n",
      "Epoch 34 Training Loss: 0.021320716835631175 Validation Loss: 0.011681051701355803\n",
      "Accuracy: 98.0999984741211\n",
      "Epoch 35 Training Loss: 0.020546117273154474 Validation Loss: 0.011899270188781277\n",
      "Accuracy: 98.07999420166016\n",
      "Epoch 36 Training Loss: 0.020094923888454408 Validation Loss: 0.012024705458544001\n",
      "Accuracy: 98.15999603271484\n",
      "Epoch 37 Training Loss: 0.0184313981859547 Validation Loss: 0.011662020957650385\n",
      "Accuracy: 98.06999969482422\n",
      "Epoch 38 Training Loss: 0.017863692482792733 Validation Loss: 0.011622226990524117\n",
      "Accuracy: 98.18000030517578\n",
      "Epoch 39 Training Loss: 0.016730460294154304 Validation Loss: 0.011371739333029837\n",
      "Accuracy: 98.16999816894531\n",
      "Epoch 40 Training Loss: 0.016591073738668152 Validation Loss: 0.011160787246866675\n",
      "Accuracy: 98.20999908447266\n",
      "Epoch 41 Training Loss: 0.014796716803864305 Validation Loss: 0.011322531041325419\n",
      "Accuracy: 98.18999481201172\n",
      "Epoch 42 Training Loss: 0.013938020188696101 Validation Loss: 0.011456316214886707\n",
      "Accuracy: 98.25\n",
      "Epoch 43 Training Loss: 0.013970024601398715 Validation Loss: 0.01131848684329331\n",
      "Accuracy: 98.19999694824219\n",
      "Epoch 44 Training Loss: 0.013883791157713859 Validation Loss: 0.011344232943512906\n",
      "Accuracy: 98.2699966430664\n",
      "Epoch 45 Training Loss: 0.013266910957919511 Validation Loss: 0.01131532488387893\n",
      "Accuracy: 98.19999694824219\n",
      "Epoch 46 Training Loss: 0.012519496894468223 Validation Loss: 0.01139867947743187\n",
      "Accuracy: 98.19999694824219\n",
      "Epoch 47 Training Loss: 0.012019906345262522 Validation Loss: 0.011413818022325965\n",
      "Accuracy: 98.22000122070312\n",
      "Epoch 48 Training Loss: 0.011816889152317647 Validation Loss: 0.011427962422665586\n",
      "Accuracy: 98.25\n",
      "Epoch 49 Training Loss: 0.011152218142561954 Validation Loss: 0.011525044198283771\n",
      "Accuracy: 98.20999908447266\n",
      "Epoch 50 Training Loss: 0.010481996299760795 Validation Loss: 0.011362910465104506\n",
      "Accuracy: 98.23999786376953\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 50\n",
    "for epoch in range(n_epochs):\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "\n",
    "    model.train()\n",
    "    for idx, (data, target) in enumerate(train_loader):\n",
    "        data = data.view(-1, 28 * 28)\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * data.size(0)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    for idx, (data, target) in enumerate(valid_loader):\n",
    "        data = data.view(-1, 28 * 28)\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        valid_loss += loss.item() * data.size(0)\n",
    "\n",
    "    train_loss = train_loss / len(train_loader.dataset)\n",
    "    valid_loss = valid_loss / len(valid_loader.dataset)\n",
    "\n",
    "    print(f'Epoch {epoch+1} Training Loss: {train_loss} Validation Loss: {valid_loss}')\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    for idx, (data, target) in enumerate(test_loader):\n",
    "        data = data.view(-1, 28 * 28)\n",
    "        output = model(data)\n",
    "        _, pred = torch.max(output, 1)\n",
    "        correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "\n",
    "    print(f'Accuracy: {correct / len(test_data) * 100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 위의 모델 저장\n",
    "torch.save(model, f'./models/mnist_model_{n_epochs}.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 7\n",
      "Prediction: 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 테스트 데이터를 사용하여 모델을 테스트함\n",
    "with torch.no_grad():  ## torch.no_grad() 하면 gradiente 계산을 수행안함\n",
    "    r = random.randint(0, len(test_data) - 1)\n",
    "    X_single_data = test_data.test_data[r].view(-1, 28 * 28).float().to('cpu')\n",
    "    Y_single_data = test_data.test_labels[r].to('cpu')\n",
    "\n",
    "    print(f'Label: {Y_single_data.item()}')\n",
    "    single_prediction = model(X_single_data)\n",
    "    print(f'Prediction: {torch.argmax(single_prediction, 1).item()}')\n",
    "    \n",
    "    plt.imshow(test_data.test_data[r].view(28, 28), cmap='Greys', interpolation='nearest')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
